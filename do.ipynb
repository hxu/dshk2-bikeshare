{
 "metadata": {
  "name": "",
  "signature": "sha256:56b8de5bfec70a3fb94a2105e5502661807f8edf3ac8207a2631166f16103dee"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.metrics import make_scorer\n",
      "from sklearn.cross_validation import KFold, cross_val_score\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "\n",
      "TEST_FILE = 'data/test.csv'\n",
      "TRAIN_FILE = 'data/train.csv'\n",
      "\n",
      "\n",
      "def get_train_data():\n",
      "    # Loads the training data, but splits the y from the X\n",
      "    df = pd.read_csv(TRAIN_FILE)\n",
      "    return df.iloc[:, 0:9], df.iloc[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, we should set up some sort of testing framework, so that we can benchmark our progress as we go\n",
      "# The evaluation metric is Root mean squared logarithmic error.\n",
      "def rmsele(actual, pred):\n",
      "    \"\"\"\n",
      "    Given a column of predictions and a column of actuals, calculate the RMSELE\n",
      "    \"\"\"\n",
      "    squared_errors = (np.log(pred + 1) - np.log(actual + 1)) ** 2\n",
      "    mean_squared = np.sum(squared_errors) / len(squared_errors)\n",
      "    return np.sqrt(mean_squared)\n",
      "\n",
      "# This helper function will make a callable that we can use in cross_val_score\n",
      "rmsele_scorer = make_scorer(rmsele, greater_is_better=False)\n",
      "\n",
      "# Fill in some of the parameters on cross_val_score\n",
      "def perform_cv(estimator, X, y):\n",
      "    return cross_val_score(estimator, X, y, scoring=rmsele_scorer, cv=5, verbose=1)\n",
      "\n",
      "# And for grid_search\n",
      "def perform_grid_search(estimator, parameters, X, y):\n",
      "    grid_search = GridSearchCV(estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
      "    grid_search.fit(X, y)\n",
      "    return grid_search\n",
      "\n",
      "# Custom Ridge to floor predictions at 0\n",
      "class FlooredRidge(Ridge):\n",
      "    def predict(self, X, *args, **kwargs):\n",
      "        pred = super(FlooredRidge, self).predict(X, *args, **kwargs)\n",
      "        pred[pred < 0] = 0\n",
      "        return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets just train a basic model so that we can test if our scoring and cross validation framework works well.\n",
      "# We'll use a Ridge regression, which is a form of linear regression\n",
      "X, y = get_train_data()\n",
      "# Subset the X to just use temp, atemp, and workingday\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "ridge_estimator = Ridge(normalize=True)\n",
      "scores = cross_val_score(ridge_estimator, Xhat, y, scoring=rmsele_scorer, cv=5, verbose=1)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try a simple grid search with the estimator\n",
      "parameters = {'alpha': np.logspace(0, 2, 10)}\n",
      "grid = GridSearchCV(ridge_estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
      "grid.fit(Xhat, y)\n",
      "grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now lets move on to the actual transformation of the inputs\n",
      "# First, not every estimator we'll use will have the \"normalize\" keyword\n",
      "# So let's break it out into a transformer, so that we have better control over it\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "Xhat = normalize.fit_transform(Xhat)\n",
      "scores = perform_cv(ridge_estimator, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we have the beginnings of a multi-step pipeline\n",
      "# Scikit lets you wrap each of these steps into a Pipeline object, so you just have to run fit / predict once\n",
      "# instead of manually feeding the data from one transformer to the next\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "array([        nan, -1.4796492 ,         nan, -1.33777294, -1.24175033])"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Additionally, you can perform grid search over all of the steps of the pipeline\n",
      "# So you don't have to tune each step manually\n",
      "# The pipeline exposes the underlying steps' parameters like so:\n",
      "# ridge__alpha, and normalize__with_mean\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "parameters = {'ridge__alpha': np.logspace(0, 3, 10)}\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "grid = GridSearchCV(pipeline, parameters, scoring=rmsele_scorer, cv=5)\n",
      "grid.fit(Xhat, y)\n",
      "grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "[mean: nan, std: nan, params: {'ridge__alpha': 1.0},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 2.1544346900318838},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 4.6415888336127784},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 10.0},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 21.544346900318832},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 46.415888336127772},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 100.0},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 215.44346900318823},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 464.15888336127773},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 1000.0}]"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets move on to including more features in our model\n",
      "# We probably want to use a factor like Season in our model, but it's\n",
      "# a categorical feature, and we'll need to convert it to a series of booleans\n",
      "one_hot = OneHotEncoder()\n",
      "season = one_hot.fit_transform(X['season'].reshape(X.shape[0], 1)).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We then have to join this with the other variables\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "Xhat = np.hstack([X[['temp', 'atemp', 'humidity']], season])\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "array([        nan, -1.44375715,         nan, -1.27959987, -1.2144014 ])"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Actually there's a faster way of doing this with the argument 'categorical_features'\n",
      "class ToArray(BaseEstimator, TransformerMixin):\n",
      "    def __init__(self):\n",
      "        pass\n",
      "    \n",
      "    def fit(self, X, y=None):\n",
      "        return self\n",
      "    \n",
      "    def transform(self, X):\n",
      "        return X.toarray()\n",
      "        \n",
      "Xhat = X[['season', 'temp', 'atemp', 'humidity']]\n",
      "one_hot = OneHotEncoder(categorical_features=[0])\n",
      "desparse = ToArray()\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "pipeline = Pipeline([('onehot', one_hot), ('desparse', desparse), ('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "array([        nan, -1.44375715,         nan, -1.27959987, -1.2144014 ])"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}