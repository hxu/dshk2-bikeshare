{
 "metadata": {
  "name": "",
  "signature": "sha256:f368caed89ca65f50def194af30240b99e6abe5ad777555fab7dcca514ddd93e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.metrics import make_scorer\n",
      "from sklearn.cross_validation import KFold, cross_val_score\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "\n",
      "TEST_FILE = 'data/test.csv'\n",
      "TRAIN_FILE = 'data/train.csv'\n",
      "\n",
      "\n",
      "def get_train_data():\n",
      "    # Loads the training data, but splits the y from the X\n",
      "    df = pd.read_csv(TRAIN_FILE)\n",
      "    return df.iloc[:, 0:9], df.iloc[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, we should set up some sort of testing framework, so that we can benchmark our progress as we go\n",
      "# The evaluation metric is Root mean squared logarithmic error.\n",
      "def rmsele(pred, actual):\n",
      "    \"\"\"\n",
      "    Given a column of predictions and a column of actuals, calculate the RMSELE\n",
      "    \"\"\"\n",
      "    squared_errors = (np.log(pred + 1) - np.log(actual + 1)) ** 2\n",
      "    mean_squared = np.sum(squared_errors) / len(squared_errors)\n",
      "    return np.sqrt(mean_squared)\n",
      "\n",
      "# This helper function will make a callable that we can use in cross_val_score\n",
      "rmsele_scorer = make_scorer(rmsele, greater_is_better=False)\n",
      "\n",
      "# Fill in some of the parameters on cross_val_score\n",
      "def perform_cv(estimator, X, y):\n",
      "    return cross_val_score(estimator, X, y, scoring=rmsele_scorer, cv=5, verbose=1)\n",
      "\n",
      "# And for grid_search\n",
      "def perform_grid_search(estimator, parameters, X, y):\n",
      "    grid_search = GridSearchCV(estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
      "    grid_search.fit(X, y)\n",
      "    return grid_search"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets just train a basic model so that we can test if our scoring and cross validation framework works well.\n",
      "# We'll use a Ridge regression, which is a form of linear regression\n",
      "X, y = get_train_data()\n",
      "# Subset the X to just use temp, atemp, and workingday\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "five_fold = KFold(y.shape[0], 5)\n",
      "ridge_estimator = Ridge(normalize=True)\n",
      "scores = cross_val_score(ridge_estimator, Xhat, y, scoring=rmsele_scorer, cv=5, verbose=1)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "array([-1.76528587, -1.47399835, -1.45131085, -1.35599072, -1.27766039])"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try a simple grid search with the estimator\n",
      "parameters = {'alpha': np.logspace(0, 2, 10)}\n",
      "grid = GridSearchCV(ridge_estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
      "grid.fit(Xhat, y)\n",
      "grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "[mean: -1.46488, std: 0.16578, params: {'alpha': 1.0},\n",
        " mean: -1.48670, std: 0.17716, params: {'alpha': 1.6681005372000588},\n",
        " mean: -1.50817, std: 0.18952, params: {'alpha': 2.7825594022071245},\n",
        " mean: -1.52705, std: 0.20109, params: {'alpha': 4.6415888336127784},\n",
        " mean: -1.54209, std: 0.21051, params: {'alpha': 7.7426368268112693},\n",
        " mean: -1.55312, std: 0.21737, params: {'alpha': 12.915496650148841},\n",
        " mean: -1.56072, std: 0.22201, params: {'alpha': 21.544346900318832},\n",
        " mean: -1.56571, std: 0.22499, params: {'alpha': 35.938136638046259},\n",
        " mean: -1.56888, std: 0.22685, params: {'alpha': 59.948425031894089},\n",
        " mean: -1.57085, std: 0.22800, params: {'alpha': 100.0}]"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now lets move on to the actual transformation of the inputs\n",
      "# We probably want to use a factor like Season in our model, but it's\n",
      "# a categorical feature, and we'll need to convert it to a series of booleans\n",
      "one_hot = OneHotEncoder()\n",
      "season = one_hot.fit_transform(X['season'].reshape(X.shape[0], 1))\n",
      "pd.DataFrame(season.toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}