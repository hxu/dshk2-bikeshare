{
 "metadata": {
  "name": "",
  "signature": "sha256:6e8f3e188df9bb4d76aea94ca18a4728d30ebc8ee1e8b62402fc5b7c08414abf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.metrics import make_scorer\n",
      "from sklearn.cross_validation import KFold, cross_val_score\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer\n",
      "from sklearn.pipeline import Pipeline, FeatureUnion\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "\n",
      "TEST_FILE = 'data/test.csv'\n",
      "TRAIN_FILE = 'data/train.csv'\n",
      "\n",
      "\n",
      "def get_train_data():\n",
      "    # Loads the training data, but splits the y from the X\n",
      "    df = pd.read_csv(TRAIN_FILE)\n",
      "    return df.iloc[:, 0:9], df.iloc[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, we should set up some sort of testing framework, so that we can benchmark our progress as we go\n",
      "# The evaluation metric is Root mean squared logarithmic error.\n",
      "def rmsele(actual, pred):\n",
      "    \"\"\"\n",
      "    Given a column of predictions and a column of actuals, calculate the RMSELE\n",
      "    \"\"\"\n",
      "    squared_errors = (np.log(pred + 1) - np.log(actual + 1)) ** 2\n",
      "    mean_squared = np.sum(squared_errors) / len(squared_errors)\n",
      "    return np.sqrt(mean_squared)\n",
      "\n",
      "# This helper function will make a callable that we can use in cross_val_score\n",
      "rmsele_scorer = make_scorer(rmsele, greater_is_better=False)\n",
      "\n",
      "# Fill in some of the parameters on cross_val_score\n",
      "def perform_cv(estimator, X, y):\n",
      "    return cross_val_score(estimator, X, y, scoring=rmsele_scorer, cv=5, verbose=1)\n",
      "\n",
      "# And for grid_search\n",
      "def perform_grid_search(estimator, parameters, X, y):\n",
      "    grid_search = GridSearchCV(estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
      "    grid_search.fit(X, y)\n",
      "    return grid_search\n",
      "\n",
      "# Custom Ridge to floor predictions at 0\n",
      "class FlooredRidge(Ridge):\n",
      "    def predict(self, X, *args, **kwargs):\n",
      "        pred = super(FlooredRidge, self).predict(X, *args, **kwargs)\n",
      "        pred[pred < 0] = 0\n",
      "        return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets just train a basic model so that we can test if our scoring and cross validation framework works well.\n",
      "# We'll use a Ridge regression, which is a form of linear regression\n",
      "X, y = get_train_data()\n",
      "# Subset the X to just use temp, atemp, and workingday\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "ridge_estimator = Ridge(normalize=True)\n",
      "scores = cross_val_score(ridge_estimator, Xhat, y, scoring=rmsele_scorer, cv=5, verbose=1)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([-1.76528587, -1.47399835, -1.45131085, -1.35599072, -1.27766039])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try a simple grid search with the estimator\n",
      "parameters = {'alpha': np.logspace(0, 2, 10)}\n",
      "grid = GridSearchCV(ridge_estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
      "grid.fit(Xhat, y)\n",
      "grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[mean: -1.46488, std: 0.16578, params: {'alpha': 1.0},\n",
        " mean: -1.48670, std: 0.17716, params: {'alpha': 1.6681005372000588},\n",
        " mean: -1.50817, std: 0.18952, params: {'alpha': 2.7825594022071245},\n",
        " mean: -1.52705, std: 0.20109, params: {'alpha': 4.6415888336127784},\n",
        " mean: -1.54209, std: 0.21051, params: {'alpha': 7.7426368268112693},\n",
        " mean: -1.55312, std: 0.21737, params: {'alpha': 12.915496650148841},\n",
        " mean: -1.56072, std: 0.22201, params: {'alpha': 21.544346900318832},\n",
        " mean: -1.56571, std: 0.22499, params: {'alpha': 35.938136638046259},\n",
        " mean: -1.56888, std: 0.22685, params: {'alpha': 59.948425031894089},\n",
        " mean: -1.57085, std: 0.22800, params: {'alpha': 100.0}]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now lets move on to the actual transformation of the inputs\n",
      "# First, not every estimator we'll use will have the \"normalize\" keyword\n",
      "# So let's break it out into a transformer, so that we have better control over it\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "Xhat = normalize.fit_transform(Xhat)\n",
      "scores = perform_cv(ridge_estimator, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([        nan, -1.47964703,         nan, -1.33777304, -1.241764  ])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we have the beginnings of a multi-step pipeline\n",
      "# Scikit lets you wrap each of these steps into a Pipeline object, so you just have to run fit / predict once\n",
      "# instead of manually feeding the data from one transformer to the next\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([        nan, -1.4796492 ,         nan, -1.33777294, -1.24175033])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Additionally, you can perform grid search over all of the steps of the pipeline\n",
      "# So you don't have to tune each step manually\n",
      "# The pipeline exposes the underlying steps' parameters like so:\n",
      "# ridge__alpha, and normalize__with_mean\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "parameters = {'ridge__alpha': np.logspace(0, 3, 10)}\n",
      "Xhat = X[['temp', 'atemp', 'humidity']]\n",
      "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "grid = GridSearchCV(pipeline, parameters, scoring=rmsele_scorer, cv=5)\n",
      "grid.fit(Xhat, y)\n",
      "grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[mean: nan, std: nan, params: {'ridge__alpha': 1.0},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 2.1544346900318838},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 4.6415888336127784},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 10.0},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 21.544346900318832},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 46.415888336127772},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 100.0},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 215.44346900318823},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 464.15888336127773},\n",
        " mean: nan, std: nan, params: {'ridge__alpha': 1000.0}]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets move on to including more features in our model\n",
      "# We probably want to use a factor like Season in our model, but it's\n",
      "# a categorical feature, and we'll need to convert it to a series of booleans\n",
      "one_hot = OneHotEncoder()\n",
      "season = one_hot.fit_transform(X['season'].reshape(X.shape[0], 1)).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We then have to join this with the other variables\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = Ridge()\n",
      "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "Xhat = np.hstack([X[['temp', 'atemp', 'humidity']], season])\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([        nan, -1.44375715,         nan, -1.27959987, -1.2144014 ])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Actually there's a faster way of doing this with the argument 'categorical_features'\n",
      "class ToArray(BaseEstimator, TransformerMixin):\n",
      "    # We need this because OneHotEncoder returns a sparse array, and normalize requires a non-sparse array\n",
      "    def __init__(self):\n",
      "        pass\n",
      "    \n",
      "    def fit(self, X, y=None):\n",
      "        return self\n",
      "    \n",
      "    def transform(self, X):\n",
      "        return X.toarray()\n",
      "        \n",
      "Xhat = X[['season', 'weather', 'temp', 'atemp', 'humidity']]\n",
      "# I think it needs to be 5 here, because it assumes that '0' is a possible value for an int datatype\n",
      "# Should probably specify the data types in read_csv\n",
      "one_hot = OneHotEncoder(n_values=[5, 5], categorical_features=[0, 1])\n",
      "desparse = ToArray()\n",
      "normalize = StandardScaler()\n",
      "ridge_estimator = FlooredRidge()\n",
      "pipeline = Pipeline([('onehot', one_hot), ('desparse', desparse), ('normalize', normalize), ('ridge', ridge_estimator)])\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([-1.66213   , -1.44178361, -1.68336829, -1.27575541, -1.21552556])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OK, so now we've got a pipeline that does one-hot encoding of two categorical variables\n",
      "# and then normalizes the variables\n",
      "# But actually we're not supposed to normalize the the dummy variables.\n",
      "# So we need some way of only normalizing non-dummy variables\n",
      "\n",
      "# Oops, actually the CV splitting converts the Pandas DF to an array, so we can't rely\n",
      "# on the normalize having the proper column names\n",
      "class SelectiveNormalize(StandardScaler):\n",
      "    def __init__(self, cols, copy=True, with_mean=True, with_std=True):\n",
      "        self.cols = cols\n",
      "        super(SelectiveNormalize, self).__init__(copy, with_mean, with_std)\n",
      "    \n",
      "    def fit(self, X, y=None):\n",
      "        subset = X[:, self.cols]\n",
      "        return super(SelectiveNormalize, self).fit(subset, y)\n",
      "        \n",
      "    def transform(self, X):\n",
      "        subset = X[:, self.cols]\n",
      "        normalized = super(SelectiveNormalize, self).transform(subset)\n",
      "        others = [col for col in range(X.shape[1]) if col not in self.cols]\n",
      "        res = np.hstack([normalized, X[:, others]])\n",
      "        return res\n",
      "\n",
      "Xhat = X[['season', 'weather', 'temp', 'atemp', 'humidity']]\n",
      "one_hot = OneHotEncoder(n_values=[5, 5], categorical_features=[3, 4])\n",
      "normalize = SelectiveNormalize([2, 3, 4])\n",
      "desparse = ToArray()\n",
      "ridge_estimator = FlooredRidge()\n",
      "pipeline = Pipeline([('normalize', normalize), ('onehot', one_hot), ('desparse', desparse), ('ridge', ridge_estimator)])\n",
      "scores = perform_cv(pipeline, Xhat, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([-1.6619715 , -1.44185074, -1.68307809, -1.27580582, -1.21554233])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets try tackling the date column now.  The time of day is probably really important\n",
      "# So we need some way of extracting the hour\n",
      "# We'll use a FeatureUnion to do this, to demonstrate the functionality\n",
      "def get_train_data():\n",
      "    # Loads the training data, but splits the y from the X\n",
      "    df = pd.read_csv(TRAIN_FILE, parse_dates=['datetime'])\n",
      "    return df.iloc[:, 0:9], df.iloc[:,-1]\n",
      "\n",
      "\n",
      "class SelectColumns(BaseEstimator, TransformerMixin):\n",
      "    \"\"\"\n",
      "    Passes on a subset of columns from an input ndarray\n",
      "    \"\"\"\n",
      "    def __init__(self, cols):\n",
      "        self.cols = cols\n",
      "    \n",
      "    def fit(self, X, y=None):\n",
      "        return self\n",
      "    \n",
      "    def transform(self, X):\n",
      "        return X[:, self.cols]\n",
      "    \n",
      "\n",
      "class ExtractHour(BaseEstimator, TransformerMixin):\n",
      "    \"\"\"\n",
      "    Extracts hour from a datetime series\n",
      "    \"\"\"\n",
      "    def __init__(self):\n",
      "        pass\n",
      "    \n",
      "    def fit(self, X, y=None):\n",
      "        return self\n",
      "    \n",
      "    def transform(self, X):\n",
      "        res = np.zeros(X.shape)\n",
      "        for xx in xrange(X.shape[0]):\n",
      "            res[xx] = X[xx, 0].hour\n",
      "        return res.reshape(res.shape[0], 1)\n",
      "    \n",
      "\n",
      "class CastType(BaseEstimator, TransformerMixin):\n",
      "    def __init__(self, cast_to):\n",
      "        self.cast_to = cast_to\n",
      "        \n",
      "    def fit(self, X, y=None):\n",
      "        return self\n",
      "    \n",
      "    def transform(self, X):\n",
      "        return X.astype(self.cast_to)\n",
      "\n",
      "X, y = get_train_data()\n",
      "# Reminder of the columns:\n",
      "# ['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed']\n",
      "select_date = SelectColumns([0])\n",
      "select_others = SelectColumns(range(1, 9))\n",
      "cast_float = CastType(np.float64)\n",
      "one_hot = OneHotEncoder(n_values=[5, 5], categorical_features=[0, 3])\n",
      "get_hour = ExtractHour()\n",
      "normalize = SelectiveNormalize(range(2, 8))\n",
      "desparse = ToArray()\n",
      "ridge_estimator = FlooredRidge()\n",
      "\n",
      "hour_feature = Pipeline([('select_date', select_date), ('get_hour', get_hour)])\n",
      "other_features = Pipeline([('select_others', select_others), ('cast_float', cast_float), ('onehot', one_hot), ('desparse', desparse)])\n",
      "join_features = FeatureUnion([('hour', hour_feature), ('others', other_features)])\n",
      "predict = Pipeline([('featurize', join_features), ('estimator', ridge_estimator)])\n",
      "scores = perform_cv(predict, X, y)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([-1.44751221, -1.34066812, -1.64296928, -1.12128857, -1.06266446])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}